#  Vision-Based Vehicle Trajectory Estimation System

[![Python](https://img.shields.io/badge/Python-3.9+-blue?logo=python)](https://www.python.org/)  
[![YOLOv3](https://img.shields.io/badge/YOLOv3-Object%20Detection-green)](https://pjreddie.com/darknet/yolo/)  
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

##  Overview

This project implements a **vision-based vehicle trajectory estimation system** that combines **computer vision, GPS, and Doppler-based relative velocity estimation** for real-time risk assessment.  

Vehicles are detected from single or multiple cameras, and **license plates are used as stable reference points** (center + orientation). After target tracking builds continuous trajectories, **Taylor expansion** (local polynomial approximation) is applied for short-term trajectory prediction. GPS and Doppler (or visual proxy) provide relative velocity estimation, enabling calculation of **dynamic safe distances** and **collision risk alerts** in real time.

---

##  Repository Layout

```text
.
â”œâ”€ src/
â”‚  â”œâ”€ detectors/                         # Detection and license plate processing
â”‚  â”‚  â”œâ”€ yolo_v3.py                      # Vehicle detection with YOLOv3 (load_model, infer)
â”‚  â”‚  â”œâ”€ license_plate.py                # License plate detection with heavy preprocessing
â”‚  â”‚  â””â”€ plate_locator.py                # ROI refinement, plate angle estimation, center extraction
â”‚  â”œâ”€ tracking/                          # Multi-object tracking
â”‚  â”‚  â””â”€ kalman.py                       # Kalman filter (ID consistency, not final prediction)
â”‚  â”œâ”€ trajectory/                        # Trajectory & short-term prediction
â”‚  â”‚  â”œâ”€ buffer.py                       # Sliding window buffer {t, x, y, Î¸} per track_id
â”‚  â”‚  â””â”€ taylor_predictor.py             # Taylor expansion (0.5â€“1.5s short-term prediction)
â”‚  â”œâ”€ fusion/                            # Sensor fusion
â”‚  â”‚  â”œâ”€ gps.py                          # GPS parsing (ego velocity, heading, timestamp)
â”‚  â”‚  â””â”€ doppler.py                      # Radial relative velocity estimation
â”‚  â”œâ”€ risk/                              # Risk assessment
â”‚  â”‚  â”œâ”€ ttc.py                          # Time-To-Collision calculation
â”‚  â”‚  â””â”€ safe_distance.py                # Safe distance (physics-based / zone-based)
â”‚  â”œâ”€ viz/                               # Visualization
â”‚  â”‚  â”œâ”€ overlay.py                      # Overlay boxes, IDs, trajectories, alerts
â”‚  â”‚  â””â”€ palette.py                      # Color palette and style configs
â”‚  â””â”€ utils/                             # Shared utilities
â”‚     â”œâ”€ geometry.py                     # Projection, distance, angle conversions
â”‚     â”œâ”€ smoothing.py                    # EMA, median filter, hysteresis smoothing
â”‚     â””â”€ metrics.py                      # Evaluation metrics (ADE, FDE, IDF1, etc.)
â”œâ”€ configs/
â”‚  â”œâ”€ model.yaml                         # Model paths, input sizes, detector thresholds
â”‚  â””â”€ thresholds.yaml                    # Risk thresholds (TTC, safe distance, zone boundaries)
â””â”€ README.md
```

## System Architecture

```text
Input
 â”œâ”€ Cameras (single/multi-view)
 â”œâ”€ GPS (ego-velocity, heading, timestamp) 
        â–¼
Perception
 â”œâ”€ Vehicle Detection (YOLOv3)
 â”œâ”€ License Plate Detection & Preprocessing
 â””â”€ Plate Center & Orientation Extraction
        â”‚
        â–¼
Tracking
 â””â”€ Multi-Object Tracking (Kalman filter for ID consistency)
        â”‚
        â–¼
Trajectory & Prediction
 â”œâ”€ Trajectory Buffer (per track_id)
 â””â”€ Short-term Prediction (Taylor Expansion, 0.5â€“1.5s horizon)
        â”‚
        â–¼
Sensor Fusion
 â”œâ”€ Ego velocity & heading from GPS
 â”œâ”€ Relative radial velocity from Doppler
 â””â”€ Range & range-rate estimation
        â”‚
        â–¼
Risk Assessment
 â”œâ”€ TTC (Time-To-Collision)
 â”œâ”€ Dynamic Safe Distance (physics-based or zone-based)
 â””â”€ Risk Alert Decision
        â”‚
        â–¼
Visualization & Output
 â”œâ”€ Overlays (bbox, ID, trajectory, risk)
 â””â”€ Alerts (color, audio, logs)
```


##  Workflow (Step-by-Step)

The system processes video streams and sensor inputs step by step:

---

1. **Vehicle Detection**  
   - Detect vehicles from raw video frames using **YOLOv3**.  
   - Extract license plate regions with **preprocessing** (contrast enhancement, denoising, edge operations).  
   - Use license plate **centers** as stable reference points for tracking.  

   *Example:*  
   <p align="center">
     <img src="https://github.com/user-attachments/assets/1d25c0da-4d3f-437e-ba57-0d6853113141" 
          alt="Vehicle detection and plate extraction" width="260" height="200">
   </p>

---

2. **Tracking (ID Consistency)**  
   - Maintain consistent IDs across frames using a **Kalman filter** (state vector: `[x, y, vx, vy]`).  
   - Ensures temporal continuity and prevents ID switching during occlusion or detection noise.  

   *Visualization:*  
   <p align="center">
     <img src="https://www.researchgate.net/publication/354627620/figure/fig4/AS:1080241044889618@1634560943438/Working-principle-of-Kalman-filter.jpg" 
          alt="Working principle of Kalman filter" width="600" height="453">
   </p>  

   *Source:* [ResearchGate â€“ Working principle of Kalman filter](https://www.researchgate.net/figure/Working-principle-of-Kalman-filter_fig4_354627620)

---

3. **Trajectory Buffer & Taylor Expansion**  
   - Store trajectory history in a **sliding buffer** `{t, x, y, Î¸}` per track_id.  
   - Apply **Taylor expansion (local polynomial approximation)** for **short-term trajectory prediction** (0.5â€“1.5s horizon).  

   **Formula:**  
   $$
   x(t) \approx x_0 + v_x \Delta t + \tfrac{1}{2} a_x \Delta t^2
   $$

   $$
   y(t) \approx y_0 + v_y \Delta t + \tfrac{1}{2} a_y \Delta t^2
   $$

---

4. **Sensor Fusion (GPS + Doppler)**  
   - **GPS** provides ego-velocity $v_{ego}$ and heading $\psi$.  
   - **Doppler (or visual proxy)** provides **radial relative velocity** $v_{rel}$.  
   - Fusion yields **range and range-rate** estimation.  

   **Formula:**  
   $$
   v_{rel} = (v_{target} - v_{ego}) \cdot \hat{r}
   $$

---

5. **Risk Assessment**

The system evaluates collision risk with **two complementary strategies**:

---

###  Physics-based Safe Distance

$$
d_{safe} = v_{ego} \cdot t_{react} + \frac{v_{ego}^2}{2a_{brake}}
$$
[
- **$v_{ego}$** â€“ ego vehicle speed (è‡ªè»Šé€Ÿåº¦)  
- **$t_{react}$** â€“ reaction time (åæ‡‰æ™‚é–“ï¼Œä¾‹å¦‚ 1s)  
- **$a_{brake}$** â€“ maximum deceleration (æœ€å¤§æ¸›é€Ÿåº¦ï¼Œä¾‹å¦‚ 7 m/sÂ²)  

ğŸ’¡ **Interpretation:**  
Safe distance = **reaction distance + braking distance**.  
If the actual gap is smaller than $d_{safe}$, even full braking may not avoid a collision.

---

###  Time-to-Collision (TTC)

$$
TTC = \frac{distance}{\max(\epsilon, v_{closing})}
$$

- **$distance$** â€“ current distance to the lead vehicle (è‡ªè»Šèˆ‡å‰è»Šçš„è·é›¢)  
- **$v_{closing}$** â€“ closing speed (ç›¸å°æ¥è¿‘é€Ÿåº¦ï¼Œè‹¥å‰è»Šæ¯”ä½ æ…¢å‰‡ç‚ºæ­£å€¼)  
- **$\epsilon$** â€“ small constant to avoid division by zero  

ğŸ’¡ **Interpretation:**  
TTC estimates *how many seconds remain before collision* if both vehicles keep their current speed.  
A smaller TTC implies higher collision risk.

---

###  Alert Logic

âš ï¸ A **risk alert** is triggered if **either** condition is met:

- $distance < d_{safe}$ (**too close for safe braking**)  
- **OR**  
- $TTC < \tau$ (**collision expected within threshold time, e.g., 2s**)  

---

###  Summary

- **Safe Distance** â†’ *â€œDo I have enough space to stop safely?â€*  
- **TTC** â†’ *â€œIf nothing changes, how soon will I crash?â€*  
- Combining both yields robustness:  
  - *Safe Distance* covers braking dynamics.  
  - *TTC* covers relative timing of collision.

---

6. **Visualization & Alerts**  
   - Overlay predicted trajectories, risk zones, and alert signals.  
   - High-risk vehicles are marked in **red**, with optional audio/haptic alerts.  

   *Example:*  
   <p align="center">
     <img width="694" height="401" alt="Risk Visualization" src="https://github.com/user-attachments/assets/8658f11e-3da1-4606-9cfd-c3e5afeef054" />
   </p>

---

##  System Diagram

```mermaid
flowchart LR
    A[Camera Frames] --> B[YOLOv3 Detection];
    B --> C[License Plate Extraction];
    C --> D[Tracking (Kalman)];
    D --> E[Trajectory Buffer];
    E --> F[Taylor Expansion Prediction];
    F --> G[Fusion => GPS + Doppler];
    G --> H[Risk Assessment];
    H --> I[Visualization & Alerts];
```

