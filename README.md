#  Vision-Based Vehicle Trajectory Estimation System

[![Python](https://img.shields.io/badge/Python-3.9+-blue?logo=python)](https://www.python.org/)  
[![YOLOv3](https://img.shields.io/badge/YOLOv3-Object%20Detection-green)](https://pjreddie.com/darknet/yolo/)  
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

---

##  Overview

This project implements a **vision-based vehicle trajectory estimation system** that combines **computer vision, GPS, and Doppler-based relative velocity estimation** for real-time risk assessment.  

Vehicles are detected from single or multiple cameras, and **license plates are used as stable reference points** (center + orientation). After target tracking builds continuous trajectories, **Taylor expansion** (local polynomial approximation) is applied for short-term trajectory prediction. GPS and Doppler (or visual proxy) provide relative velocity estimation, enabling calculation of **dynamic safe distances** and **collision risk alerts** in real time.

---

##  Repository Layout

```text
.
â”œâ”€ src/
â”‚  â”œâ”€ detectors/                         # Detection and license plate processing
â”‚  â”‚  â”œâ”€ yolo_v3.py                      # Vehicle detection with YOLOv3 (load_model, infer)
â”‚  â”‚  â”œâ”€ license_plate.py                # License plate detection with heavy preprocessing
â”‚  â”‚  â””â”€ plate_locator.py                # ROI refinement, plate angle estimation, center extraction
â”‚  â”œâ”€ tracking/                          # Multi-object tracking
â”‚  â”‚  â””â”€ kalman.py                       # Kalman filter (ID consistency, not final prediction)
â”‚  â”œâ”€ trajectory/                        # Trajectory & short-term prediction
â”‚  â”‚  â”œâ”€ buffer.py                       # Sliding window buffer {t, x, y, Î¸} per track_id
â”‚  â”‚  â””â”€ taylor_predictor.py             # Taylor expansion (0.5â€“1.5s short-term prediction)
â”‚  â”œâ”€ fusion/                            # Sensor fusion
â”‚  â”‚  â”œâ”€ gps.py                          # GPS parsing (ego velocity, heading, timestamp)
â”‚  â”‚  â””â”€ doppler.py                      # Radial relative velocity estimation
â”‚  â”œâ”€ risk/                              # Risk assessment
â”‚  â”‚  â”œâ”€ ttc.py                          # Time-To-Collision calculation
â”‚  â”‚  â””â”€ safe_distance.py                # Safe distance (physics-based / zone-based)
â”‚  â”œâ”€ viz/                               # Visualization
â”‚  â”‚  â”œâ”€ overlay.py                      # Overlay boxes, IDs, trajectories, alerts
â”‚  â”‚  â””â”€ palette.py                      # Color palette and style configs
â”‚  â””â”€ utils/                             # Shared utilities
â”‚     â”œâ”€ geometry.py                     # Projection, distance, angle conversions
â”‚     â”œâ”€ smoothing.py                    # EMA, median filter, hysteresis smoothing
â”‚     â””â”€ metrics.py                      # Evaluation metrics (ADE, FDE, IDF1, etc.)
â”œâ”€ configs/
â”‚  â”œâ”€ model.yaml                         # Model paths, input sizes, detector thresholds
â”‚  â””â”€ thresholds.yaml                    # Risk thresholds (TTC, safe distance, zone boundaries)
â””â”€ README.md
```

## System Architecture

```text
Input
 â”œâ”€ Cameras (single/multi-view)
 â”œâ”€ GPS (ego-velocity, heading, timestamp) 
        â–¼
Perception
 â”œâ”€ Vehicle Detection (YOLOv3)
 â”œâ”€ License Plate Detection & Preprocessing
 â””â”€ Plate Center & Orientation Extraction
        â”‚
        â–¼
Tracking
 â””â”€ Multi-Object Tracking (Kalman filter for ID consistency)
        â”‚
        â–¼
Trajectory & Prediction
 â”œâ”€ Trajectory Buffer (per track_id)
 â””â”€ Short-term Prediction (Taylor Expansion, 0.5â€“1.5s horizon)
        â”‚
        â–¼
Sensor Fusion
 â”œâ”€ Ego velocity & heading from GPS
 â”œâ”€ Relative radial velocity from Doppler
 â””â”€ Range & range-rate estimation
        â”‚
        â–¼
Risk Assessment
 â”œâ”€ TTC (Time-To-Collision)
 â”œâ”€ Dynamic Safe Distance (physics-based or zone-based)
 â””â”€ Risk Alert Decision
        â”‚
        â–¼
Visualization & Output
 â”œâ”€ Overlays (bbox, ID, trajectory, risk)
 â””â”€ Alerts (color, audio, logs)
```


## ðŸ”„ Workflow (Step-by-Step)

The system processes video streams and sensor inputs step by step:

1. **Vehicle Detection**  
   - Detect vehicles from raw video frames using YOLOv3.  
   - Extract license plate regions with preprocessing (contrast, denoising, edge ops).  
   - Plate centers serve as **stable reference points**.  
   - *Example:*  
     ![Vehicle detection and plate extraction](<img width="204" height="155" alt="image" src="https://github.com/user-attachments/assets/1d25c0da-4d3f-437e-ba57-0d6853113141" />
)

---

2. **Tracking (ID Consistency)**  
   - Maintain consistent IDs across frames using a Kalman filter (state: `[x, y, vx, vy]`).  
   - Prevents ID switching when occlusion or detection jitter occurs.
   
---

3. **Trajectory Buffer & Taylor Expansion**  
   - Store trajectory history in a sliding buffer `{t, x, y, Î¸}`.  
   - Apply **Taylor expansion** for short-term trajectory prediction (0.5â€“1.5s).  

   **Formula:**  
   $$
   x(t) \approx x_0 + v_x \Delta t + \tfrac{1}{2} a_x \Delta t^2 \\
   y(t) \approx y_0 + v_y \Delta t + \tfrac{1}{2} a_y \Delta t^2
   $$

---

4. **Sensor Fusion (GPS + Doppler)**  
   - GPS provides ego-velocity $v_{ego}$ and heading $\psi$.  
   - Doppler (or visual proxy) provides **radial relative velocity** $v_{rel}$.  
   - Fusion yields **range and range-rate** estimation.  

   **Formula:**  
   $$
   v_{rel} = (v_{target} - v_{ego}) \cdot \hat{r}
   $$

---

5. **Risk Assessment**  
   - Two strategies:  
     - **Physics-based safe distance:**  
       $$
       d_{safe} = v_{ego} \cdot t_{react} + \frac{v_{ego}^2}{2a_{brake}}
       $$  
     - **Time-to-Collision (TTC):**  
       $$
       TTC = \frac{distance}{\max(\epsilon, v_{closing})}
       $$  

   - Risk alert is triggered if:  
     - $distance < d_{safe}$, OR  
     - $TTC < \tau$ (threshold).  

---

6. **Visualization & Alerts**  
   - Overlay predicted trajectories, risk zones, and alert signals.  
   - High-risk vehicles are marked in **red** with optional audio/haptic alerts.  
   - *Example:*  
     ![Final overlay visualization](<img width="694" height="401" alt="image" src="https://github.com/user-attachments/assets/8658f11e-3da1-4606-9cfd-c3e5afeef054" />

---

##  System Diagram

```mermaid
flowchart LR
    A[Camera Frames] --> B[YOLOv3 Detection]
    B --> C[License Plate Extraction]
    C --> D[Tracking (Kalman)]
    D --> E[Trajectory Buffer]
    E --> F[Taylor Expansion Prediction]
    F --> G[Fusion (GPS + Doppler)]
    G --> H[Risk Assessment]
    H --> I[Visualization & Alerts]

```
